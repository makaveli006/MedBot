#### We use Pinecone, a cloud-based vector database, to handle the large-scale chunking and storage of a 700-page book, as a local database would be inefficient and lack scalability for this task.

#### Famous LLM ops platforms are aws bedrock and GCP vertex AI

#### In this project
1) OpenAI = LLM
2) Langchain = Orchestration Framework
3) PineCone = Vectordb
4) Flask = Webapp
5) Github = Version controlling
6) AWS = simple deployment and CI/CD deployment